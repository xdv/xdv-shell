// File: shell_lexer.ds - This file is part of XDV
// Copyright (c) 2026 Dust LLC, and Contributors
// Description:
//   Shell Lexer - deterministic packet lexer for command words.

forge ShellLexerErrors {
    const ERR_OK: UInt32 = 0;
    const ERR_INVALID_TOKEN: UInt32 = 1;
    const ERR_EOF: UInt32 = 2;
    const ERR_TOO_LONG: UInt32 = 3;
    const ERR_DOMAIN_NOT_AVAILABLE: UInt32 = 100;
}

forge ShellLexer {

    const TOKEN_WORD: UInt32 = 1;
    const TOKEN_PIPE: UInt32 = 2;
    const TOKEN_REDIR_IN: UInt32 = 3;
    const TOKEN_REDIR_OUT: UInt32 = 4;
    const TOKEN_REDIR_APPEND: UInt32 = 5;
    const TOKEN_EOF: UInt32 = 0;

    const PACK_LEN_FACTOR: UInt64 = 100000000000;
    const MAX_TOKEN_LEN: UInt64 = 64;

    proc K::packet_length(packet: UInt64) -> UInt64 {
        if packet == 0 {
            return 0;
        } else {
            return packet / PACK_LEN_FACTOR;
        }
    }

    proc K::init(input: UInt64) -> UInt32 {
        let length = packet_length(input);
        if length == 0 {
            return ERR_EOF;
        } else {
            if length > MAX_TOKEN_LEN {
                return ERR_TOO_LONG;
            } else {
                return ERR_OK;
            }
        }
    }

    proc K::classify_token_value(value: UInt64) -> UInt32 {
        let length = packet_length(value);
        if length == 0 {
            return TOKEN_EOF;
        } else {
            if length > MAX_TOKEN_LEN {
                return TOKEN_EOF;
            } else {
                return TOKEN_WORD;
            }
        }
    }

    proc K::next_token(input: UInt64) -> UInt32 {
        return classify_token_value(input);
    }

    proc K::get_token_value(input: UInt64) -> UInt64 {
        return input;
    }

    proc K::peek_token(input: UInt64) -> UInt32 {
        return next_token(input);
    }

    proc K::reset() -> UInt32 {
        return ERR_OK;
    }

    proc K::tokenize(input: UInt64, output: UInt64) -> UInt32 {
        let init_result = init(input);
        if init_result == ERR_OK {
            return classify_token_value(input);
        } else {
            return TOKEN_EOF;
        }
    }
}
